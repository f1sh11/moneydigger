import json, requests, itertools, time
from collections import Counter, defaultdict
from bs4 import BeautifulSoup, NavigableString
from itertools import combinations, islice
from math import comb

STANDARD_TIERS = {
    "å´­æ–°å‡ºå‚": (0.00, 0.07),
    "ç•¥æœ‰ç£¨æŸ": (0.07, 0.15),
    "ä¹…ç»æ²™åœº": (0.15, 0.38),
    "ç ´æŸä¸å ª": (0.38, 0.45),
    "æˆ˜ç—•ç´¯ç´¯": (0.45, 1.00),
}

RARITY_ORDER = ["æ¶ˆè´¹çº§", "å·¥ä¸šçº§", "å†›è§„çº§", "å—é™", "ä¿å¯†", "éšç§˜"]
price_cache = {}
request_counter = {"count": 0}
loaded_goods_ids = set()

ALLOWED_CASES = {"åå†²æ­¦å™¨ç®±"} 

def get_float_tier(value):
    for tier, (min_f, max_f) in STANDARD_TIERS.items():
        if min_f <= value < max_f:
            return tier
    return None

def load_input_pool_by_case():
    data = load_data()
    pool = []
    for case in data:
        if case["case_name"] not in ALLOWED_CASES:
            continue
        for skin in case["skins"]:
            next_rarity = get_next_rarity(skin.get("rarity"))
            if not next_rarity or not skin.get("name") or not skin.get("wear_goods_ids"):
                continue
            for wear, gid in skin["wear_goods_ids"].items():
                if "StatTrak" in wear:
                    continue
                pool.append({
                    "name": skin["name"],
                    "wear": wear,
                    "goods_id": gid,
                    "case_name": case["case_name"],
                    "next_rarity": next_rarity,
                    "float": (skin.get("min_float", 0) + skin.get("max_float", 1)) / 2
                })
    return pool

def load_data(path="converted_cases_with_card_ranges_strict.json"):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def get_next_rarity(current):
    try:
        return RARITY_ORDER[RARITY_ORDER.index(current) + 1]
    except:
        return None

def fetch_wear_prices(goods_id, cookies):
    if goods_id in loaded_goods_ids:
        print(f"ğŸ›‘ è·³è¿‡é‡å¤ goods_id: {goods_id}")
        return

    loaded_goods_ids.add(goods_id)
    url = f"https://buff.163.com/goods/{goods_id}?from=market"
    print(f"ğŸ”ã€fetch_wear_pricesã€‘å¼€å§‹è¯·æ±‚: {url}")
    request_counter["count"] += 1
    print(f"ğŸ“¥ å½“å‰è¯·æ±‚æ€»æ•°: {request_counter['count']}")

    headers = {"User-Agent": "Mozilla/5.0"}
    while True:
        time.sleep(1)
        try:
            res = requests.get(url, headers=headers, cookies=cookies, timeout=10)
            if res.status_code == 200:
                soup = BeautifulSoup(res.text, "html5lib")
                count = 0
                for btn in soup.select("div.scope-btns a"):
                    price_tag = btn.select_one("span.custom-currency")
                    if price_tag and price_tag.has_attr("data-price"):
                        price = float(price_tag["data-price"])
                        for child in btn.children:
                            if isinstance(child, NavigableString) and child.strip():
                                tier = child.strip()
                                if "StatTrak" in tier:  # âœ… å¿½ç•¥ StatTrak æ¡ç›®
                                    continue
                                key = f"{goods_id}_{tier}"
                                price_cache[key] = price
                                count += 1
                                print(f"âœ… ä»·æ ¼ç¼“å­˜: {key} = Â¥{price}")
                                break
                print(f"ğŸ¯ æ€»è®¡ç¼“å­˜ç£¨æŸä»·æ ¼æ•°: {count} for goods_id={goods_id}")
                return
            else:
                print(f"\nâŒ è¯·æ±‚å¤±è´¥ {res.status_code}ï¼Œç­‰å¾…é‡è¯•ä¸­...")
                time.sleep(2)
        except Exception as e:
            print(f"\nâš ï¸ å¼‚å¸¸: {e}ï¼Œç­‰å¾…é‡è¯•ä¸­...")
            time.sleep(2)
            
def calc_float_thresholds(min_f, max_f):
    """
    è®¡ç®—æ‰€æœ‰ç£¨æŸå‹çº¿çš„å¹³å‡ float é™åˆ¶ã€‚
    è¿”å›å­—å…¸å½¢å¼ï¼Œå¦‚ {"å´­æ–°å‡ºå‚": 0.0933, ...}
    """
    thresholds = {}
    for tier, (low, high) in STANDARD_TIERS.items():
        threshold = (high - low) / (max_f - min_f)  # ä»å…¬å¼æ¨åå‘æ±‚ avg_float ä¸Šé™
        thresholds[tier] = round(threshold, 6)
    return thresholds

def get_price(goods_id, wear, cookies):
    key = f"{goods_id}_{wear}"
    if key in price_cache:
        return price_cache[key]

    # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰è¯¥ goods_id ä¸‹ä»»æ„ç£¨æŸï¼Œè¯´æ˜è¿˜æ²¡åŠ è½½è¿‡ â†’ å»çˆ¬ä¸€æ¬¡
    if not any(f"{goods_id}_{tier}" in price_cache for tier in STANDARD_TIERS):
        fetch_wear_prices(goods_id, cookies)

    return price_cache.get(key)

def find_possible_outputs(combo, all_data):
    target_rarities = set(item["next_rarity"] for item in combo)
    outputs = []
    for case in all_data:
        for skin in case.get("skins", []):
            if skin.get("rarity") not in target_rarities:
                continue
            if not skin.get("name") or not skin.get("wear_goods_ids"):
                continue
            outputs.append({
                "name": skin["name"],
                "wear_goods_ids": skin["wear_goods_ids"],
                "case_name": case["case_name"]  # ğŸ‘ˆ åŠ ä¸Šè¿™ä¸ª
            })
    return outputs

def preload_prices(pool, all_data, cookies):
    goods_to_fetch = {}
    seen_skins = set()

    print("ğŸ“¦ [é¢„å¤„ç†] å¼€å§‹æ„å»ºå¾…è¯·æ±‚çš®è‚¤åˆ—è¡¨...")

    # ä»è¾“å…¥æ± ä¸­æ·»åŠ çš®è‚¤ï¼ˆç”¨äºåˆæˆï¼‰
    for item in pool:
        unique_key = f"{item['name']}|{item['case_name']}"
        if unique_key in seen_skins:
            continue
        seen_skins.add(unique_key)
        goods_to_fetch[unique_key] = item["goods_id"]

    # è¾“å‡ºçš®è‚¤ä¸­ä¹Ÿè¦åˆå¹¶ï¼ˆç”¨äºæ”¶ç›Šè®¡ç®—ï¼‰
    relevant_cases = set(i["case_name"] for i in pool)
    target_rarities = set(i["next_rarity"] for i in pool)

    for case in all_data:
        if case["case_name"] not in relevant_cases:
            continue
        for skin in case.get("skins", []):
            if skin.get("rarity") not in target_rarities:
                continue
            wear_ids = skin.get("wear_goods_ids", {})
            if not wear_ids:
                continue

            unique_key = f"{skin['name']}|{case['case_name']}"
            if unique_key in seen_skins:
                continue
            seen_skins.add(unique_key)

            # é€‰æ‹©æœ€ä¼˜ goods_id é¡µé¢
            preferred = ["å´­æ–°å‡ºå‚", "ç•¥æœ‰ç£¨æŸ", "ä¹…ç»æ²™åœº"]
            gid = None
            for tier in preferred:
                if tier in wear_ids:
                    gid = wear_ids[tier]
                    break
            if not gid:
                gid = next(iter(wear_ids.values()), None)

            if gid:
                goods_to_fetch[unique_key] = gid

    print(f"\nğŸ’¾ å®é™…éœ€è¦è¯·æ±‚é¡µé¢æ•°: {len(goods_to_fetch)}\n")

    # è¯·æ±‚é˜¶æ®µ
    for i, (key, gid) in enumerate(goods_to_fetch.items(), 1):
        print(f"â¡ï¸ [ç¬¬ {i}/{len(goods_to_fetch)} é¡¹] {key} -> goods_id={gid}")
        if gid in loaded_goods_ids:
            print(f"ğŸŸ¡ goods_id={gid} å·²åœ¨ç¼“å­˜ä¸­ï¼Œè·³è¿‡è¯·æ±‚")
            continue
        fetch_wear_prices(gid, cookies)

def load_input_pool(limit):
    data = load_data()
    pool = []
    count = 0
    for case in data:
        for skin in case["skins"]:
            next_rarity = get_next_rarity(skin.get("rarity"))
            if not next_rarity or not skin.get("name") or not skin.get("wear_goods_ids"):
                continue

            entries = []
            for wear, gid in skin["wear_goods_ids"].items():
                if "StatTrak" in wear:
                    continue
                entries.append({
                    "name": skin["name"],
                    "wear": wear,
                    "goods_id": gid,
                    "case_name": case["case_name"],
                    "next_rarity": next_rarity,
                    "float": (skin.get("min_float", 0) + skin.get("max_float", 1)) / 2
                })

            pool.extend(entries)
            count += 1
            if count >= limit:
                return pool
    return pool

def print_progress(current, total):
    bar_len = 30
    filled_len = int(bar_len * current // total)
    bar = 'â–ˆ' * filled_len + '-' * (bar_len - filled_len)
    print(f"\râ³ è¿›åº¦ [{bar}] {current}/{total}", end='')

def float_to_tier(f):
    for tier, (low, high) in STANDARD_TIERS.items():
        if low <= f < high:
            return tier
    return None

def get_output_max_price(output_skins, cookies):
    max_price = 0
    for s in output_skins:
        price_map = fetch_wear_prices(s["goods_id"], cookies)
        if price_map:
            max_price = max(max_price, *price_map.values())
    return max_price

def should_skip(combo, avg_float, total_price, valid_outputs, cookies):
    if not valid_outputs:
        return "æ— è¾“å‡ºçš®è‚¤"

    if any(p is None or p <= 0 for p in [get_price(i["goods_id"], i["wear"], cookies) for i in combo]):
        return "å­˜åœ¨ä»·æ ¼ç¼ºå¤±"

    float_tier_thresholds = calc_float_thresholds(0.00, 0.75)  # é»˜è®¤æ ‡å‡†åŒºé—´
    target_tier = float_to_tier(avg_float)
    if target_tier and avg_float > float_tier_thresholds.get(target_tier, 1):
        return f"float è¶…è¿‡ {target_tier} å‹çº¿"

    output_max_price = get_output_max_price(valid_outputs, cookies)
    if total_price > output_max_price:
        return "æˆæœ¬é«˜äºæœ€é«˜å”®ä»·"

    float_tier = float_to_tier(avg_float)
    if not float_tier:
        return "float åŒºé—´å¼‚å¸¸"

    for s in valid_outputs:
        wear_ids = s.get("wear_goods_ids", {})
        gid = wear_ids.get("å´­æ–°å‡ºå‚") or next(iter(wear_ids.values()), None)
        if not gid:
            continue
        prices = fetch_wear_prices(gid, cookies)
        if float_tier in prices and prices[float_tier] > 0:
            return None  # âœ… åˆæ³•ç»„åˆ
    return "ç›®æ ‡ float åŒºé—´æ— ä»·æ ¼"

def simulate_mixed_combos(pool, cookies):
    print(f"ğŸ§ª æ­£åœ¨æ„é€ ç»„åˆï¼ˆä¸é‡å¤ & ä¸è€ƒè™‘é¡ºåºï¼‰...")

    ONLY_PRINT_COMBO_COUNT = True  # ğŸ‘ˆ å¼€å…³æ§åˆ¶ï¼šTrue = åªæ‰“å°ç»„åˆæ•°é‡ï¼Œä¸æ¨¡æ‹Ÿ

    rarity_groups = defaultdict(list)
    for item in pool:
        rarity_groups[item["next_rarity"]].append(item)

    total_combos = 0
    results = []
    data = load_data()
    start = time.time()
    accepted = 0
    skipped_by_cost = 0

    for rarity, group in rarity_groups.items():
        if len(group) < 10:
            continue

        group_combos_count = comb(len(group), 10)
        print(f"ğŸ“¦ ç¨€æœ‰åº¦ [{rarity}] ç»„åŒ…å« {len(group)} ä¸ªçš®è‚¤ï¼Œç†è®ºç»„åˆæ•°: {group_combos_count:,}")

        group_combos_count = comb(len(group), 10)
        print(f"ğŸ“Š â†’ ç†è®ºç»„åˆæ•°: {group_combos_count:,}")
        total_combos += group_combos_count
        continue
    
        total_combos += len(combos)

        if ONLY_PRINT_COMBO_COUNT:
            continue  # âœ… è·³è¿‡æ¨¡æ‹Ÿé€»è¾‘ï¼Œåªæ‰“å°ç»„åˆä¿¡æ¯

        for combo in combos:
            try:
                total_price = sum(get_price(item["goods_id"], item["wear"], cookies) for item in combo)
            except:
                continue

            output_skins = find_possible_outputs(combo, data)
            valid_outputs = [s for s in output_skins if s.get("wear_goods_ids")]
            if not valid_outputs:
                continue

            max_output_price = get_output_max_price(valid_outputs, cookies)
            if total_price > max_output_price:
                skipped_by_cost += 1
                continue

            floats = [item["float"] for item in combo if "float" in item]
            avg_float = sum(floats) / 10 if floats else 0.5

            output_values = []
            for s in valid_outputs:
                gid = s["goods_id"]
                price_map = fetch_wear_prices(gid, cookies)
                if not price_map:
                    continue
                min_f, max_f = s["min_float"], s["max_float"]
                final_float = avg_float * (max_f - min_f) + min_f
                matched_tier = get_float_tier(final_float)
                price = price_map.get(matched_tier)
                if price:
                    output_values.append(price)

            if not output_values:
                continue

            expected_value = sum(output_values) / len(output_values)
            net = expected_value - total_price

            results.append({
                "ç»„åˆ": [f"{i['name']}({i['wear']})" for i in combo],
                "float": round(avg_float, 5),
                "æˆæœ¬": round(total_price, 2),
                "æœŸæœ›": round(expected_value, 2),
                "å‡€æ”¶ç›Š": round(net, 2),
                "æ¥æºç®±ç»„åˆ": list({i["case_name"] for i in combo})
            })
            accepted += 1

    duration = round(time.time() - start, 2)
    if ONLY_PRINT_COMBO_COUNT:
        print(f"\nâœ… å·²å®Œæˆæ‰€æœ‰ç»„åˆåˆ†ç»„ç»Ÿè®¡ï¼Œæ€»ç»„åˆæ•° â‰ˆ {total_combos:,}ï¼Œè€—æ—¶ {duration} ç§’ã€‚")
        return None

    print(f"\nâœ… æ¨¡æ‹Ÿå®Œæˆï¼šæ€»ç»„åˆæ•°çº¦ {total_combos:,}ï¼Œæ¥å— {accepted} ä¸ªï¼Œè·³è¿‡ï¼ˆæˆæœ¬ï¼‰{skipped_by_cost}ï¼Œè€—æ—¶ {duration} ç§’ã€‚")
    results.sort(key=lambda x: x["å‡€æ”¶ç›Š"], reverse=True)
    return results

def run_mixed_mode():
    with open("buff_state.json", "r", encoding="utf-8") as f:
        state = json.load(f)
    cookies = {c['name']: c['value'] for c in state['cookies'] if 'buff.163.com' in c['domain']}

    pool = load_input_pool_by_case()  # âœ… æ”¹ä¸ºæŒ‰ç®±å­åŠ è½½
    print(f"ğŸ§© è¾“å…¥æ± çš®è‚¤æ•°é‡: {len(pool)}")
    
    data = load_data()
    preload_prices(pool, data, cookies)
    results = simulate_mixed_combos(pool, cookies)
    if not results:
        print("ğŸš« å½“å‰æ¨¡å¼æœªè¿”å›ç»“æœï¼ˆä»…æ‰“å°ç»„åˆæ•°æˆ–å‘ç”Ÿä¸­æ–­ï¼‰")
        return
    for i, r in enumerate(results[:3], 1):
        print(f"\nğŸ† Top {i}")
        for line in r["ç»„åˆ"]:
            print(f" - {line}")
        print(f"ğŸ¯ float: {r['float']}")
        print(f"ğŸ’° æˆæœ¬: Â¥{r['æˆæœ¬']} | ğŸ“¦ æœŸæœ›: Â¥{r['æœŸæœ›']} | ğŸ“ˆ å‡€æ”¶ç›Š: Â¥{r['å‡€æ”¶ç›Š']}")
        print(f"ğŸ“¦ æ¥æºç®±ç»„åˆ: {' + '.join(r['æ¥æºç®±ç»„åˆ'])}")

if __name__ == "__main__":
    run_mixed_mode()
